{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2YgaZ7B22QWXhmrNfvSpo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnahitaZahediNameghi/InitialCoding/blob/main/Preprocessing_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sentence = \"These days, I've struggling with some difficulties. I like the sunlight because it gives me good energy and puts me in a jolly mood, however, the sun is disappearing for a couple of days and it is not the condition I am interested into.\""
      ],
      "metadata": {
        "id": "oRlUu2o5qoFP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pTV28Kh9sUfI",
        "outputId": "2f55ed07-0c37-4a12-99d1-b92651487012"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "g6F_Gh6vs1zj",
        "outputId": "b504ab61-e4a8-4fe4-bedf-d6ba44b97180"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xVjDN4jvtQMH",
        "outputId": "d6f46a1d-958f-49e2-c72a-6387501b320a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "LYxKCnuPtZKN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JUYO4Ak0uAvp",
        "outputId": "5b121599-31c8-4ae1-ca5f-e6eb66a04fa7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'up', 'and', 'very', 'because', 'or', 'did', \"wasn't\", \"hasn't\", 'our', 've', 'him', 'hasn', \"hadn't\", 'but', 'some', 'during', 'how', 'as', 'both', 'them', 'he', 'o', 'its', 'weren', 'too', 'which', 'had', 'while', 'an', 're', 'are', 'me', \"she's\", \"that'll\", 'being', 'over', 'why', 'we', 'all', 'y', 'through', 's', 'himself', 'not', 'ourselves', \"couldn't\", 'don', \"didn't\", 'down', 'to', 'against', 'that', 'herself', 'between', 'if', 'was', 'her', 'itself', 'from', \"aren't\", 'such', 'when', 'more', \"you've\", 'own', 'i', 'you', 'shan', 'these', 'whom', \"you'd\", 'hadn', 'for', \"isn't\", 'should', 'what', \"shouldn't\", \"doesn't\", 'couldn', 'will', 'nor', 'mightn', 'wasn', 'do', 'under', 'she', 'my', 'yourselves', 'haven', 'yourself', 'can', 'myself', 'who', 'where', 'wouldn', 'of', \"wouldn't\", 'm', 'again', 'than', 'yours', 'won', 'into', 'your', 'just', 'they', 'mustn', 'this', 'doing', 'on', 'a', 'below', 'most', \"should've\", 'about', 'further', 'out', 'hers', 'shouldn', 'those', 'd', 'does', 'be', 'have', 'in', 'ain', 'themselves', 'there', \"you're\", 'has', \"mightn't\", 'needn', 'each', 'here', 'having', 'no', 'now', 'above', 'so', 'his', 'ours', 'is', \"shan't\", 'the', \"you'll\", \"mustn't\", 'll', 'same', 'aren', \"needn't\", 'theirs', 'before', 'until', 'been', 'any', 'isn', 'didn', 'other', 'then', 'at', 'few', 'by', 'ma', 'off', 'doesn', \"it's\", 'am', \"don't\", 'it', 'were', 'their', 'only', \"won't\", 'once', \"weren't\", 'after', \"haven't\", 't', 'with'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "ZhBi94qLuT-A"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the sentence into words\n",
        "words = word_tokenize(Sentence)"
      ],
      "metadata": {
        "id": "wQvHvfWkwh--"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stopwords\n",
        "filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
        "print(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "elkjA-kqwu1x",
        "outputId": "84ed373d-981b-49c2-cf56-6c441cfd53a3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['days', ',', \"'ve\", 'struggling', 'difficulties', '.', 'like', 'sunlight', 'gives', 'good', 'energy', 'puts', 'jolly', 'mood', ',', 'however', ',', 'sun', 'disappearing', 'couple', 'days', 'condition', 'interested', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join the filtered words to form a new sentence\n",
        "filtered_sentence = ' '.join(filtered_words)\n",
        "print(\"Original Sentence:\", Sentence)\n",
        "print(\"Filtered Sentence:\", filtered_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PIhyV4ymxpGf",
        "outputId": "f9527f1d-cbe9-4878-e9d1-4c2bc9a7071e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: These days, I've struggling with some difficulties. I like the sunlight because it gives me good energy and puts me in a jolly mood, however, the sun is disappearing for a couple of days and it is not the condition I am interested into.\n",
            "Filtered Sentence: days , 've struggling difficulties . like sunlight gives good energy puts jolly mood , however , sun disappearing couple days condition interested .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(input_string):\n",
        "    # Create a translation table to map each punctuation character to None\n",
        "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
        "\n",
        "    # Use translate() to remove punctuation from the input string\n",
        "    no_punct = input_string.translate(translator)\n",
        "\n",
        "    return no_punct"
      ],
      "metadata": {
        "id": "eemr_nB7yuSu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuation from the sentence\n",
        "cleaned_sentence = remove_punctuation(Sentence)\n",
        "print(\"Cleaned Sentence:\", cleaned_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yPm-Ns1XzArg",
        "outputId": "e7c3be5b-3849-448a-e8b6-812873b113ef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Sentence: These days Ive struggling with some difficulties I like the sunlight because it gives me good energy and puts me in a jolly mood however the sun is disappearing for a couple of days and it is not the condition I am interested into\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(cleaned_sentence)"
      ],
      "metadata": {
        "id": "8s6Th0FmzhEl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
        "print(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Nh98Qo3w0ZMj",
        "outputId": "9f47656e-17a1-40a4-f9ac-c52b053ccb8f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['days', 'Ive', 'struggling', 'difficulties', 'like', 'sunlight', 'gives', 'good', 'energy', 'puts', 'jolly', 'mood', 'however', 'sun', 'disappearing', 'couple', 'days', 'condition', 'interested']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lowercase_sentence = filtered_words.lower() --> AttributeError: 'list' object has no attribute 'lower'"
      ],
      "metadata": {
        "id": "S_oAocCa1tpM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert each word to lowercase\n",
        "lowercase_words = [word.lower() for word in filtered_words]\n",
        "print(\"Lowercased Sentence with word_tokenize():\", lowercase_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TOi0uadb2HcL",
        "outputId": "f2980d97-8950-4144-bb25-55d40e8bffba"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercased Sentence with word_tokenize(): ['days', 'ive', 'struggling', 'difficulties', 'like', 'sunlight', 'gives', 'good', 'energy', 'puts', 'jolly', 'mood', 'however', 'sun', 'disappearing', 'couple', 'days', 'condition', 'interested']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "uoJvGcsZ3ejU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download WordNet data (if not already downloaded)\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "07USd8Dh3nsL",
        "outputId": "c4e1bad7-1c5a-4259-e98a-71b492ec211a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentence\n",
        "sentence = \"The dogs are barking loudly.\"\n",
        "# Tokenize the sentence into words\n",
        "words = word_tokenize(sentence)"
      ],
      "metadata": {
        "id": "aIfMGy1u3ucw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the WordNet lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "aY6MoHwt34sx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatize each word in the sentence\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "print(\"Lemmatized Sentence:\", lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3xfIUwXk3706",
        "outputId": "5295c7e9-8752-4e0b-d66c-eec12891df0c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Sentence: ['The', 'dog', 'are', 'barking', 'loudly', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "# Example sentence\n",
        "sentence = \"The dogs are barking loudly.\"\n",
        "# Tokenize the sentence into words\n",
        "words = word_tokenize(sentence)\n",
        "# Initialize the Porter stemmer\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "GQyoelEF4V1y"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stem each word in the sentence\n",
        "stemmed_words = [stemmer.stem(word) for word in words]"
      ],
      "metadata": {
        "id": "k9otjR5N4eLC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I2ca93pK4qMD",
        "outputId": "b1cba836-e505-4fd8-e8f6-248f4ad38d67"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'dog', 'are', 'bark', 'loudli', '.']\n"
          ]
        }
      ]
    }
  ]
}